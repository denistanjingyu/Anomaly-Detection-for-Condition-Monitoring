{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Autoencoder_Current.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkJ5zgW1z5Gs",
        "outputId": "c27acb82-a4b4-4798-e461-31a214be8f63"
      },
      "source": [
        "!pip install pyod"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyod\n",
            "  Downloading pyod-0.9.0.tar.gz (105 kB)\n",
            "\u001b[?25l\r\u001b[K     |███                             | 10 kB 25.9 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 20 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 30 kB 31.4 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 40 kB 23.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 51 kB 19.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 61 kB 14.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 71 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 81 kB 16.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 92 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 102 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 105 kB 14.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyod) (1.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from pyod) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.7/dist-packages (from pyod) (1.19.5)\n",
            "Requirement already satisfied: numba>=0.35 in /usr/local/lib/python3.7/dist-packages (from pyod) (0.51.2)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.7/dist-packages (from pyod) (1.1.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from pyod) (1.4.1)\n",
            "Requirement already satisfied: scikit_learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from pyod) (0.22.2.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pyod) (1.15.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from pyod) (0.10.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.35->pyod) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.35->pyod) (57.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25->pyod) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25->pyod) (2018.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyod) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyod) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyod) (0.10.0)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels->pyod) (0.5.1)\n",
            "Building wheels for collected packages: pyod\n",
            "  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyod: filename=pyod-0.9.0-py3-none-any.whl size=122560 sha256=eabc969d99f01ae1f0b8a5144b0f9ac0018154c58939ed370feef5ff4e91b8f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/5f/59/5984a6116a4d19aee28d8ebeffd431364ce1cf21eb73a6ad34\n",
            "Successfully built pyod\n",
            "Installing collected packages: pyod\n",
            "Successfully installed pyod-0.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZwfOk2Gy9Rf",
        "outputId": "0584b1dd-9958-4302-c376-4abddbb8065a"
      },
      "source": [
        "\"\"\"Anomaly Detection (Autoencoder).\"\"\"\n",
        "# Import relevant libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from pyod.models.auto_encoder import AutoEncoder\n",
        "\n",
        "# Time the script execution\n",
        "start = time.time()\n",
        "\n",
        "def get_excel_data(file_path):\n",
        "    \"\"\"Load excel data as Pandas DataFrame.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    file_path : string\n",
        "        Define the absolute or relative location of the Excel file.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    data : DataFrame\n",
        "        A DataFrame containing the information from the Excel file.\n",
        "\n",
        "    \"\"\"\n",
        "    data = pd.read_excel(file_path)\n",
        "\n",
        "    return data\n",
        "\n",
        "df_1 = get_excel_data('Current_Dataset_1.xlsx')\n",
        "df_2 = get_excel_data('Current_Dataset_2.xlsx')\n",
        "df_3 = get_excel_data('Current_Dataset_3.xlsx')\n",
        "df_4 = get_excel_data('Current_Dataset_4.xlsx')\n",
        "df_5 = get_excel_data('Current_Dataset_5.xlsx')\n",
        "df_6 = get_excel_data('Current_Dataset_6.xlsx')\n",
        "df_7 = get_excel_data('Current_Dataset_7.xlsx')\n",
        "df_8 = get_excel_data('Current_Dataset_8.xlsx')\n",
        "df_9 = get_excel_data('Current_Dataset_9.xlsx')\n",
        "df_10 = get_excel_data('Current_Dataset_10.xlsx')\n",
        "\n",
        "def create_model(hidden_neurons):\n",
        "    \"\"\"Create machine learning model for anomaly detection.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    hidden_neurons : int\n",
        "        The number of hidden neurons to use.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    model : Autoencoder\n",
        "        An autoencoder is a special type of neural network that copies the input values to the output values.\n",
        "    \"\"\"\n",
        "    model = AutoEncoder(hidden_neurons = hidden_neurons)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    for i in range(1, 11):\n",
        "        # Create machine learning model for anomaly detection\n",
        "        exec(f'clf_{i} = create_model(hidden_neurons = [1, 1])')\n",
        "\n",
        "        # Train the models using the data given\n",
        "        exec(f'clf_{i}.fit(df_{i}[[\"Current (Ampere)\"]])')\n",
        "        \n",
        "        # Predict the anomaly scores\n",
        "        exec(f'y_test_scores_{i} = clf_{i}.decision_function(df_{i}[[\"Current (Ampere)\"]])')\n",
        "        exec(f'y_test_scores_{i} = pd.Series(y_test_scores_{i})')\n",
        "        \n",
        "        exec(f'df_test_{i} = df_{i}[[\"Current (Ampere)\"]].copy()')\n",
        "        exec(f'df_test_{i}[\"score\"] = y_test_scores_{i}')\n",
        "        exec(f'df_test_{i}[\"cluster\"] = np.where(df_test_{i}[\"score\"] < 2, 0, 1)')\n",
        "        exec(f'df_test_{i}[\"cluster\"].value_counts()')\n",
        "\n",
        "        # Save the dataframes in CSV format\n",
        "        exec(f'df_test_{i}.to_csv(\"autoencoder_current_{i}.csv\", index = False)')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "\n",
        "# Script execution time\n",
        "print(\"\\nScript Execution Time\")\n",
        "print(\"--------------------------\")\n",
        "print('It took {0:0.1f} seconds'.format(time.time() - start))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_42 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_35 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_36 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_38 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 1)                 2         \n",
            "=================================================================\n",
            "Total params: 10\n",
            "Trainable params: 10\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.2684 - val_loss: 1.3206\n",
            "Epoch 2/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.1942 - val_loss: 1.2565\n",
            "Epoch 3/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.1435 - val_loss: 1.2125\n",
            "Epoch 4/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.1088 - val_loss: 1.1817\n",
            "Epoch 5/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0841 - val_loss: 1.1591\n",
            "Epoch 6/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0654 - val_loss: 1.1418\n",
            "Epoch 7/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0515 - val_loss: 1.1286\n",
            "Epoch 8/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0408 - val_loss: 1.1182\n",
            "Epoch 9/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0324 - val_loss: 1.1100\n",
            "Epoch 10/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0258 - val_loss: 1.1034\n",
            "Epoch 11/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0205 - val_loss: 1.0980\n",
            "Epoch 12/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0162 - val_loss: 1.0936\n",
            "Epoch 13/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0127 - val_loss: 1.0900\n",
            "Epoch 14/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0099 - val_loss: 1.0870\n",
            "Epoch 15/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0075 - val_loss: 1.0844\n",
            "Epoch 16/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0055 - val_loss: 1.0823\n",
            "Epoch 17/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0038 - val_loss: 1.0804\n",
            "Epoch 18/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0025 - val_loss: 1.0789\n",
            "Epoch 19/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 1.0013 - val_loss: 1.0775\n",
            "Epoch 20/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0002 - val_loss: 1.0763\n",
            "Epoch 21/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 1.0753\n",
            "Epoch 22/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9986 - val_loss: 1.0744\n",
            "Epoch 23/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9980 - val_loss: 1.0737\n",
            "Epoch 24/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9974 - val_loss: 1.0730\n",
            "Epoch 25/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9969 - val_loss: 1.0723\n",
            "Epoch 26/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9965 - val_loss: 1.0718\n",
            "Epoch 27/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9961 - val_loss: 1.0713\n",
            "Epoch 28/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9958 - val_loss: 1.0709\n",
            "Epoch 29/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9955 - val_loss: 1.0705\n",
            "Epoch 30/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9952 - val_loss: 1.0701\n",
            "Epoch 31/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.9950 - val_loss: 1.0698\n",
            "Epoch 32/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.9948 - val_loss: 1.0695\n",
            "Epoch 33/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9946 - val_loss: 1.0693\n",
            "Epoch 34/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9944 - val_loss: 1.0691\n",
            "Epoch 35/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9943 - val_loss: 1.0688\n",
            "Epoch 36/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.9942 - val_loss: 1.0686\n",
            "Epoch 37/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9940 - val_loss: 1.0685\n",
            "Epoch 38/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9939 - val_loss: 1.0683\n",
            "Epoch 39/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9938 - val_loss: 1.0681\n",
            "Epoch 40/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9938 - val_loss: 1.0680\n",
            "Epoch 41/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9937 - val_loss: 1.0679\n",
            "Epoch 42/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9936 - val_loss: 1.0678\n",
            "Epoch 43/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9936 - val_loss: 1.0677\n",
            "Epoch 44/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.9935 - val_loss: 1.0676\n",
            "Epoch 45/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9934 - val_loss: 1.0675\n",
            "Epoch 46/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9934 - val_loss: 1.0674\n",
            "Epoch 47/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9933 - val_loss: 1.0673\n",
            "Epoch 48/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9933 - val_loss: 1.0672\n",
            "Epoch 49/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9933 - val_loss: 1.0672\n",
            "Epoch 50/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9932 - val_loss: 1.0671\n",
            "Epoch 51/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9932 - val_loss: 1.0671\n",
            "Epoch 52/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9932 - val_loss: 1.0670\n",
            "Epoch 53/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9931 - val_loss: 1.0669\n",
            "Epoch 54/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9931 - val_loss: 1.0669\n",
            "Epoch 55/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9931 - val_loss: 1.0668\n",
            "Epoch 56/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9931 - val_loss: 1.0668\n",
            "Epoch 57/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9931 - val_loss: 1.0668\n",
            "Epoch 58/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9930 - val_loss: 1.0667\n",
            "Epoch 59/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9930 - val_loss: 1.0667\n",
            "Epoch 60/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9930 - val_loss: 1.0666\n",
            "Epoch 61/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9930 - val_loss: 1.0666\n",
            "Epoch 62/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9930 - val_loss: 1.0666\n",
            "Epoch 63/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9930 - val_loss: 1.0665\n",
            "Epoch 64/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9929 - val_loss: 1.0665\n",
            "Epoch 65/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9929 - val_loss: 1.0665\n",
            "Epoch 66/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9929 - val_loss: 1.0665\n",
            "Epoch 67/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9929 - val_loss: 1.0665\n",
            "Epoch 68/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9929 - val_loss: 1.0664\n",
            "Epoch 69/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9929 - val_loss: 1.0664\n",
            "Epoch 70/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9929 - val_loss: 1.0664\n",
            "Epoch 71/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9929 - val_loss: 1.0664\n",
            "Epoch 72/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9929 - val_loss: 1.0663\n",
            "Epoch 73/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9929 - val_loss: 1.0663\n",
            "Epoch 74/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9929 - val_loss: 1.0663\n",
            "Epoch 75/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.9929 - val_loss: 1.0663\n",
            "Epoch 76/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9929 - val_loss: 1.0663\n",
            "Epoch 77/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9929 - val_loss: 1.0663\n",
            "Epoch 78/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9928 - val_loss: 1.0663\n",
            "Epoch 79/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9928 - val_loss: 1.0662\n",
            "Epoch 80/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9928 - val_loss: 1.0662\n",
            "Epoch 81/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9928 - val_loss: 1.0662\n",
            "Epoch 82/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9928 - val_loss: 1.0662\n",
            "Epoch 83/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9928 - val_loss: 1.0662\n",
            "Epoch 84/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9928 - val_loss: 1.0662\n",
            "Epoch 85/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9928 - val_loss: 1.0662\n",
            "Epoch 86/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9928 - val_loss: 1.0662\n",
            "Epoch 87/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9928 - val_loss: 1.0662\n",
            "Epoch 88/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9928 - val_loss: 1.0661\n",
            "Epoch 89/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9928 - val_loss: 1.0661\n",
            "Epoch 90/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9928 - val_loss: 1.0661\n",
            "Epoch 91/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9928 - val_loss: 1.0661\n",
            "Epoch 92/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9928 - val_loss: 1.0661\n",
            "Epoch 93/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9928 - val_loss: 1.0661\n",
            "Epoch 94/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.9928 - val_loss: 1.0661\n",
            "Epoch 95/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9928 - val_loss: 1.0661\n",
            "Epoch 96/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9928 - val_loss: 1.0661\n",
            "Epoch 97/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9928 - val_loss: 1.0661\n",
            "Epoch 98/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9928 - val_loss: 1.0661\n",
            "Epoch 99/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9928 - val_loss: 1.0661\n",
            "Epoch 100/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9928 - val_loss: 1.0660\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_47 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_39 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_48 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_40 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_49 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_41 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_50 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_42 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_51 (Dense)             (None, 1)                 2         \n",
            "=================================================================\n",
            "Total params: 10\n",
            "Trainable params: 10\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.2597 - val_loss: 1.2868\n",
            "Epoch 2/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.1902 - val_loss: 1.2260\n",
            "Epoch 3/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.1436 - val_loss: 1.1835\n",
            "Epoch 4/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.1106 - val_loss: 1.1527\n",
            "Epoch 5/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0864 - val_loss: 1.1291\n",
            "Epoch 6/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0682 - val_loss: 1.1112\n",
            "Epoch 7/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0544 - val_loss: 1.0973\n",
            "Epoch 8/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0438 - val_loss: 1.0864\n",
            "Epoch 9/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0356 - val_loss: 1.0777\n",
            "Epoch 10/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0291 - val_loss: 1.0708\n",
            "Epoch 11/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0239 - val_loss: 1.0651\n",
            "Epoch 12/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0196 - val_loss: 1.0603\n",
            "Epoch 13/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0162 - val_loss: 1.0564\n",
            "Epoch 14/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0135 - val_loss: 1.0533\n",
            "Epoch 15/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0112 - val_loss: 1.0505\n",
            "Epoch 16/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0092 - val_loss: 1.0481\n",
            "Epoch 17/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0077 - val_loss: 1.0461\n",
            "Epoch 18/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0063 - val_loss: 1.0444\n",
            "Epoch 19/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0051 - val_loss: 1.0429\n",
            "Epoch 20/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0041 - val_loss: 1.0416\n",
            "Epoch 21/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0033 - val_loss: 1.0404\n",
            "Epoch 22/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0025 - val_loss: 1.0394\n",
            "Epoch 23/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 1.0019 - val_loss: 1.0385\n",
            "Epoch 24/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0013 - val_loss: 1.0377\n",
            "Epoch 25/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0009 - val_loss: 1.0370\n",
            "Epoch 26/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0005 - val_loss: 1.0364\n",
            "Epoch 27/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0001 - val_loss: 1.0358\n",
            "Epoch 28/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 1.0353\n",
            "Epoch 29/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 1.0348\n",
            "Epoch 30/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 1.0344\n",
            "Epoch 31/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 1.0340\n",
            "Epoch 32/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 1.0336\n",
            "Epoch 33/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9986 - val_loss: 1.0334\n",
            "Epoch 34/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9985 - val_loss: 1.0331\n",
            "Epoch 35/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 1.0328\n",
            "Epoch 36/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9982 - val_loss: 1.0326\n",
            "Epoch 37/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9981 - val_loss: 1.0324\n",
            "Epoch 38/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9980 - val_loss: 1.0322\n",
            "Epoch 39/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9979 - val_loss: 1.0320\n",
            "Epoch 40/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9978 - val_loss: 1.0318\n",
            "Epoch 41/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9977 - val_loss: 1.0316\n",
            "Epoch 42/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9977 - val_loss: 1.0315\n",
            "Epoch 43/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9976 - val_loss: 1.0314\n",
            "Epoch 44/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9976 - val_loss: 1.0312\n",
            "Epoch 45/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9975 - val_loss: 1.0311\n",
            "Epoch 46/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9975 - val_loss: 1.0310\n",
            "Epoch 47/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9974 - val_loss: 1.0309\n",
            "Epoch 48/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9974 - val_loss: 1.0308\n",
            "Epoch 49/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9973 - val_loss: 1.0307\n",
            "Epoch 50/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9973 - val_loss: 1.0306\n",
            "Epoch 51/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9973 - val_loss: 1.0306\n",
            "Epoch 52/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9973 - val_loss: 1.0305\n",
            "Epoch 53/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9972 - val_loss: 1.0304\n",
            "Epoch 54/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9972 - val_loss: 1.0304\n",
            "Epoch 55/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9972 - val_loss: 1.0303\n",
            "Epoch 56/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9972 - val_loss: 1.0303\n",
            "Epoch 57/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9972 - val_loss: 1.0302\n",
            "Epoch 58/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9971 - val_loss: 1.0301\n",
            "Epoch 59/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9971 - val_loss: 1.0301\n",
            "Epoch 60/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9971 - val_loss: 1.0300\n",
            "Epoch 61/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9971 - val_loss: 1.0300\n",
            "Epoch 62/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9971 - val_loss: 1.0299\n",
            "Epoch 63/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9971 - val_loss: 1.0299\n",
            "Epoch 64/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9971 - val_loss: 1.0299\n",
            "Epoch 65/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9970 - val_loss: 1.0298\n",
            "Epoch 66/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9970 - val_loss: 1.0298\n",
            "Epoch 67/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9970 - val_loss: 1.0298\n",
            "Epoch 68/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9970 - val_loss: 1.0297\n",
            "Epoch 69/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9970 - val_loss: 1.0297\n",
            "Epoch 70/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9970 - val_loss: 1.0297\n",
            "Epoch 71/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9970 - val_loss: 1.0296\n",
            "Epoch 72/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9970 - val_loss: 1.0296\n",
            "Epoch 73/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9970 - val_loss: 1.0296\n",
            "Epoch 74/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9970 - val_loss: 1.0296\n",
            "Epoch 75/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9970 - val_loss: 1.0296\n",
            "Epoch 76/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9970 - val_loss: 1.0295\n",
            "Epoch 77/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9970 - val_loss: 1.0295\n",
            "Epoch 78/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9970 - val_loss: 1.0295\n",
            "Epoch 79/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9970 - val_loss: 1.0295\n",
            "Epoch 80/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9969 - val_loss: 1.0295\n",
            "Epoch 81/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9969 - val_loss: 1.0294\n",
            "Epoch 82/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9969 - val_loss: 1.0294\n",
            "Epoch 83/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9969 - val_loss: 1.0294\n",
            "Epoch 84/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9969 - val_loss: 1.0294\n",
            "Epoch 85/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9969 - val_loss: 1.0294\n",
            "Epoch 86/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9969 - val_loss: 1.0294\n",
            "Epoch 87/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9969 - val_loss: 1.0293\n",
            "Epoch 88/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9969 - val_loss: 1.0293\n",
            "Epoch 89/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9969 - val_loss: 1.0293\n",
            "Epoch 90/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9969 - val_loss: 1.0293\n",
            "Epoch 91/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9969 - val_loss: 1.0293\n",
            "Epoch 92/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9969 - val_loss: 1.0293\n",
            "Epoch 93/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9969 - val_loss: 1.0292\n",
            "Epoch 94/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9969 - val_loss: 1.0292\n",
            "Epoch 95/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9969 - val_loss: 1.0292\n",
            "Epoch 96/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9969 - val_loss: 1.0292\n",
            "Epoch 97/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9969 - val_loss: 1.0292\n",
            "Epoch 98/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9969 - val_loss: 1.0292\n",
            "Epoch 99/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9969 - val_loss: 1.0292\n",
            "Epoch 100/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9969 - val_loss: 1.0292\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_52 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_43 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_53 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_44 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_54 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_45 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_55 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_46 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_56 (Dense)             (None, 1)                 2         \n",
            "=================================================================\n",
            "Total params: 10\n",
            "Trainable params: 10\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.2895 - val_loss: 1.1368\n",
            "Epoch 2/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.2101 - val_loss: 1.0712\n",
            "Epoch 3/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.1534 - val_loss: 1.0243\n",
            "Epoch 4/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.1121 - val_loss: 0.9893\n",
            "Epoch 5/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0840 - val_loss: 0.9627\n",
            "Epoch 6/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0584 - val_loss: 0.9389\n",
            "Epoch 7/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0403 - val_loss: 0.9198\n",
            "Epoch 8/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0219 - val_loss: 0.9048\n",
            "Epoch 9/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0111 - val_loss: 0.8880\n",
            "Epoch 10/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9968 - val_loss: 0.8812\n",
            "Epoch 11/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9847 - val_loss: 0.8699\n",
            "Epoch 12/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9764 - val_loss: 0.8638\n",
            "Epoch 13/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9714 - val_loss: 0.8584\n",
            "Epoch 14/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9677 - val_loss: 0.8542\n",
            "Epoch 15/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9578 - val_loss: 0.8495\n",
            "Epoch 16/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9557 - val_loss: 0.8472\n",
            "Epoch 17/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9506 - val_loss: 0.8441\n",
            "Epoch 18/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9472 - val_loss: 0.8410\n",
            "Epoch 19/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9419 - val_loss: 0.8388\n",
            "Epoch 20/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9446 - val_loss: 0.8443\n",
            "Epoch 21/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9378 - val_loss: 0.8456\n",
            "Epoch 22/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9354 - val_loss: 0.8433\n",
            "Epoch 23/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9365 - val_loss: 0.8407\n",
            "Epoch 24/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9316 - val_loss: 0.8430\n",
            "Epoch 25/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9331 - val_loss: 0.8387\n",
            "Epoch 26/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9306 - val_loss: 0.8388\n",
            "Epoch 27/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9294 - val_loss: 0.8412\n",
            "Epoch 28/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9289 - val_loss: 0.8439\n",
            "Epoch 29/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9269 - val_loss: 0.8426\n",
            "Epoch 30/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9256 - val_loss: 0.8375\n",
            "Epoch 31/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9224 - val_loss: 0.8421\n",
            "Epoch 32/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9277 - val_loss: 0.8471\n",
            "Epoch 33/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9246 - val_loss: 0.8445\n",
            "Epoch 34/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9220 - val_loss: 0.8452\n",
            "Epoch 35/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9227 - val_loss: 0.8451\n",
            "Epoch 36/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9252 - val_loss: 0.8447\n",
            "Epoch 37/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9201 - val_loss: 0.8507\n",
            "Epoch 38/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9183 - val_loss: 0.8524\n",
            "Epoch 39/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9204 - val_loss: 0.8484\n",
            "Epoch 40/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9224 - val_loss: 0.8556\n",
            "Epoch 41/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9192 - val_loss: 0.8499\n",
            "Epoch 42/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9193 - val_loss: 0.8509\n",
            "Epoch 43/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9180 - val_loss: 0.8525\n",
            "Epoch 44/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9190 - val_loss: 0.8480\n",
            "Epoch 45/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9189 - val_loss: 0.8532\n",
            "Epoch 46/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9165 - val_loss: 0.8523\n",
            "Epoch 47/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9143 - val_loss: 0.8551\n",
            "Epoch 48/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9185 - val_loss: 0.8611\n",
            "Epoch 49/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9087 - val_loss: 0.8583\n",
            "Epoch 50/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9191 - val_loss: 0.8612\n",
            "Epoch 51/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9127 - val_loss: 0.8634\n",
            "Epoch 52/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9183 - val_loss: 0.8576\n",
            "Epoch 53/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9132 - val_loss: 0.8679\n",
            "Epoch 54/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9160 - val_loss: 0.8645\n",
            "Epoch 55/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9184 - val_loss: 0.8633\n",
            "Epoch 56/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9174 - val_loss: 0.8689\n",
            "Epoch 57/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9172 - val_loss: 0.8707\n",
            "Epoch 58/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9142 - val_loss: 0.8598\n",
            "Epoch 59/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9140 - val_loss: 0.8648\n",
            "Epoch 60/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9154 - val_loss: 0.8747\n",
            "Epoch 61/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9150 - val_loss: 0.8660\n",
            "Epoch 62/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9168 - val_loss: 0.8645\n",
            "Epoch 63/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9156 - val_loss: 0.8712\n",
            "Epoch 64/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9153 - val_loss: 0.8621\n",
            "Epoch 65/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9152 - val_loss: 0.8656\n",
            "Epoch 66/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9146 - val_loss: 0.8659\n",
            "Epoch 67/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9165 - val_loss: 0.8659\n",
            "Epoch 68/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9174 - val_loss: 0.8621\n",
            "Epoch 69/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9143 - val_loss: 0.8684\n",
            "Epoch 70/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9102 - val_loss: 0.8647\n",
            "Epoch 71/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9153 - val_loss: 0.8695\n",
            "Epoch 72/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9112 - val_loss: 0.8658\n",
            "Epoch 73/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9132 - val_loss: 0.8652\n",
            "Epoch 74/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9133 - val_loss: 0.8679\n",
            "Epoch 75/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9190 - val_loss: 0.8699\n",
            "Epoch 76/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9135 - val_loss: 0.8677\n",
            "Epoch 77/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9219 - val_loss: 0.8703\n",
            "Epoch 78/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9158 - val_loss: 0.8663\n",
            "Epoch 79/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9176 - val_loss: 0.8681\n",
            "Epoch 80/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9119 - val_loss: 0.8647\n",
            "Epoch 81/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9114 - val_loss: 0.8668\n",
            "Epoch 82/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9144 - val_loss: 0.8740\n",
            "Epoch 83/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9107 - val_loss: 0.8591\n",
            "Epoch 84/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9106 - val_loss: 0.8755\n",
            "Epoch 85/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9165 - val_loss: 0.8725\n",
            "Epoch 86/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9163 - val_loss: 0.8740\n",
            "Epoch 87/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9152 - val_loss: 0.8748\n",
            "Epoch 88/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9094 - val_loss: 0.8683\n",
            "Epoch 89/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9174 - val_loss: 0.8704\n",
            "Epoch 90/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9139 - val_loss: 0.8684\n",
            "Epoch 91/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9133 - val_loss: 0.8739\n",
            "Epoch 92/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9136 - val_loss: 0.8667\n",
            "Epoch 93/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9139 - val_loss: 0.8723\n",
            "Epoch 94/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9182 - val_loss: 0.8697\n",
            "Epoch 95/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9105 - val_loss: 0.8682\n",
            "Epoch 96/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9116 - val_loss: 0.8730\n",
            "Epoch 97/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9137 - val_loss: 0.8711\n",
            "Epoch 98/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9159 - val_loss: 0.8744\n",
            "Epoch 99/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9129 - val_loss: 0.8712\n",
            "Epoch 100/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9156 - val_loss: 0.8696\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_57 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_47 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_58 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_48 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_59 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_49 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_60 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_50 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_61 (Dense)             (None, 1)                 2         \n",
            "=================================================================\n",
            "Total params: 10\n",
            "Trainable params: 10\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "252/252 [==============================] - 1s 3ms/step - loss: 1.8873 - val_loss: 1.4792\n",
            "Epoch 2/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.4179 - val_loss: 1.2809\n",
            "Epoch 3/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.2672 - val_loss: 1.1919\n",
            "Epoch 4/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.1879 - val_loss: 1.1317\n",
            "Epoch 5/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.1352 - val_loss: 1.0905\n",
            "Epoch 6/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0989 - val_loss: 1.0623\n",
            "Epoch 7/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0747 - val_loss: 1.0425\n",
            "Epoch 8/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0580 - val_loss: 1.0286\n",
            "Epoch 9/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0463 - val_loss: 1.0179\n",
            "Epoch 10/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0375 - val_loss: 1.0100\n",
            "Epoch 11/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0309 - val_loss: 1.0039\n",
            "Epoch 12/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0259 - val_loss: 0.9992\n",
            "Epoch 13/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0220 - val_loss: 0.9955\n",
            "Epoch 14/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0191 - val_loss: 0.9926\n",
            "Epoch 15/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0167 - val_loss: 0.9902\n",
            "Epoch 16/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0148 - val_loss: 0.9883\n",
            "Epoch 17/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0133 - val_loss: 0.9866\n",
            "Epoch 18/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0120 - val_loss: 0.9852\n",
            "Epoch 19/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0109 - val_loss: 0.9840\n",
            "Epoch 20/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0100 - val_loss: 0.9830\n",
            "Epoch 21/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0092 - val_loss: 0.9821\n",
            "Epoch 22/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0085 - val_loss: 0.9813\n",
            "Epoch 23/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0079 - val_loss: 0.9807\n",
            "Epoch 24/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0074 - val_loss: 0.9801\n",
            "Epoch 25/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0069 - val_loss: 0.9795\n",
            "Epoch 26/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0065 - val_loss: 0.9790\n",
            "Epoch 27/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0062 - val_loss: 0.9786\n",
            "Epoch 28/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0058 - val_loss: 0.9782\n",
            "Epoch 29/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0056 - val_loss: 0.9779\n",
            "Epoch 30/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0053 - val_loss: 0.9776\n",
            "Epoch 31/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0051 - val_loss: 0.9773\n",
            "Epoch 32/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0049 - val_loss: 0.9771\n",
            "Epoch 33/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0047 - val_loss: 0.9768\n",
            "Epoch 34/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0046 - val_loss: 0.9766\n",
            "Epoch 35/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0044 - val_loss: 0.9764\n",
            "Epoch 36/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0043 - val_loss: 0.9763\n",
            "Epoch 37/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0042 - val_loss: 0.9761\n",
            "Epoch 38/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0041 - val_loss: 0.9760\n",
            "Epoch 39/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0040 - val_loss: 0.9758\n",
            "Epoch 40/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0039 - val_loss: 0.9757\n",
            "Epoch 41/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0039 - val_loss: 0.9756\n",
            "Epoch 42/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0038 - val_loss: 0.9755\n",
            "Epoch 43/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0037 - val_loss: 0.9754\n",
            "Epoch 44/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0037 - val_loss: 0.9754\n",
            "Epoch 45/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0036 - val_loss: 0.9753\n",
            "Epoch 46/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0036 - val_loss: 0.9752\n",
            "Epoch 47/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0035 - val_loss: 0.9751\n",
            "Epoch 48/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0035 - val_loss: 0.9751\n",
            "Epoch 49/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0035 - val_loss: 0.9750\n",
            "Epoch 50/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0034 - val_loss: 0.9750\n",
            "Epoch 51/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0034 - val_loss: 0.9749\n",
            "Epoch 52/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0034 - val_loss: 0.9749\n",
            "Epoch 53/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0034 - val_loss: 0.9748\n",
            "Epoch 54/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0033 - val_loss: 0.9748\n",
            "Epoch 55/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0033 - val_loss: 0.9748\n",
            "Epoch 56/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0033 - val_loss: 0.9747\n",
            "Epoch 57/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0033 - val_loss: 0.9747\n",
            "Epoch 58/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0033 - val_loss: 0.9747\n",
            "Epoch 59/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0032 - val_loss: 0.9746\n",
            "Epoch 60/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0032 - val_loss: 0.9746\n",
            "Epoch 61/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0032 - val_loss: 0.9746\n",
            "Epoch 62/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0032 - val_loss: 0.9745\n",
            "Epoch 63/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0032 - val_loss: 0.9745\n",
            "Epoch 64/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0032 - val_loss: 0.9745\n",
            "Epoch 65/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0032 - val_loss: 0.9745\n",
            "Epoch 66/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0031 - val_loss: 0.9744\n",
            "Epoch 67/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0031 - val_loss: 0.9744\n",
            "Epoch 68/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0031 - val_loss: 0.9744\n",
            "Epoch 69/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0031 - val_loss: 0.9744\n",
            "Epoch 70/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0031 - val_loss: 0.9744\n",
            "Epoch 71/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0031 - val_loss: 0.9744\n",
            "Epoch 72/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0031 - val_loss: 0.9743\n",
            "Epoch 73/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0031 - val_loss: 0.9743\n",
            "Epoch 74/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0031 - val_loss: 0.9743\n",
            "Epoch 75/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0031 - val_loss: 0.9743\n",
            "Epoch 76/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0031 - val_loss: 0.9743\n",
            "Epoch 77/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0031 - val_loss: 0.9743\n",
            "Epoch 78/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0031 - val_loss: 0.9743\n",
            "Epoch 79/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0031 - val_loss: 0.9743\n",
            "Epoch 80/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0031 - val_loss: 0.9742\n",
            "Epoch 81/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0030 - val_loss: 0.9742\n",
            "Epoch 82/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0030 - val_loss: 0.9742\n",
            "Epoch 83/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0030 - val_loss: 0.9742\n",
            "Epoch 84/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0030 - val_loss: 0.9742\n",
            "Epoch 85/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0030 - val_loss: 0.9742\n",
            "Epoch 86/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0030 - val_loss: 0.9742\n",
            "Epoch 87/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0030 - val_loss: 0.9742\n",
            "Epoch 88/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0030 - val_loss: 0.9742\n",
            "Epoch 89/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0030 - val_loss: 0.9742\n",
            "Epoch 90/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0030 - val_loss: 0.9741\n",
            "Epoch 91/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0030 - val_loss: 0.9741\n",
            "Epoch 92/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0030 - val_loss: 0.9741\n",
            "Epoch 93/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0030 - val_loss: 0.9741\n",
            "Epoch 94/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0030 - val_loss: 0.9741\n",
            "Epoch 95/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0030 - val_loss: 0.9741\n",
            "Epoch 96/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0030 - val_loss: 0.9741\n",
            "Epoch 97/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0030 - val_loss: 0.9741\n",
            "Epoch 98/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0030 - val_loss: 0.9741\n",
            "Epoch 99/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0030 - val_loss: 0.9741\n",
            "Epoch 100/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0030 - val_loss: 0.9741\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_62 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_51 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_63 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_52 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_64 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_53 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_65 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_54 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_66 (Dense)             (None, 1)                 2         \n",
            "=================================================================\n",
            "Total params: 10\n",
            "Trainable params: 10\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.3302 - val_loss: 1.1838\n",
            "Epoch 2/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.2242 - val_loss: 1.1164\n",
            "Epoch 3/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.1673 - val_loss: 1.0734\n",
            "Epoch 4/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.1295 - val_loss: 1.0430\n",
            "Epoch 5/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.1026 - val_loss: 1.0207\n",
            "Epoch 6/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0828 - val_loss: 1.0043\n",
            "Epoch 7/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0677 - val_loss: 0.9918\n",
            "Epoch 8/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0565 - val_loss: 0.9823\n",
            "Epoch 9/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0479 - val_loss: 0.9750\n",
            "Epoch 10/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0410 - val_loss: 0.9692\n",
            "Epoch 11/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0355 - val_loss: 0.9644\n",
            "Epoch 12/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0310 - val_loss: 0.9607\n",
            "Epoch 13/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0274 - val_loss: 0.9576\n",
            "Epoch 14/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0245 - val_loss: 0.9551\n",
            "Epoch 15/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0220 - val_loss: 0.9530\n",
            "Epoch 16/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0200 - val_loss: 0.9512\n",
            "Epoch 17/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0183 - val_loss: 0.9498\n",
            "Epoch 18/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0169 - val_loss: 0.9486\n",
            "Epoch 19/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0156 - val_loss: 0.9475\n",
            "Epoch 20/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0146 - val_loss: 0.9467\n",
            "Epoch 21/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0137 - val_loss: 0.9459\n",
            "Epoch 22/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0129 - val_loss: 0.9452\n",
            "Epoch 23/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0122 - val_loss: 0.9446\n",
            "Epoch 24/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0116 - val_loss: 0.9441\n",
            "Epoch 25/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0111 - val_loss: 0.9437\n",
            "Epoch 26/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0106 - val_loss: 0.9433\n",
            "Epoch 27/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0102 - val_loss: 0.9430\n",
            "Epoch 28/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0099 - val_loss: 0.9427\n",
            "Epoch 29/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0096 - val_loss: 0.9425\n",
            "Epoch 30/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0093 - val_loss: 0.9423\n",
            "Epoch 31/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0091 - val_loss: 0.9421\n",
            "Epoch 32/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0089 - val_loss: 0.9419\n",
            "Epoch 33/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0087 - val_loss: 0.9418\n",
            "Epoch 34/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0085 - val_loss: 0.9417\n",
            "Epoch 35/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0083 - val_loss: 0.9415\n",
            "Epoch 36/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0082 - val_loss: 0.9414\n",
            "Epoch 37/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0081 - val_loss: 0.9414\n",
            "Epoch 38/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0080 - val_loss: 0.9413\n",
            "Epoch 39/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0079 - val_loss: 0.9412\n",
            "Epoch 40/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0078 - val_loss: 0.9411\n",
            "Epoch 41/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0077 - val_loss: 0.9411\n",
            "Epoch 42/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0076 - val_loss: 0.9410\n",
            "Epoch 43/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0075 - val_loss: 0.9410\n",
            "Epoch 44/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0075 - val_loss: 0.9409\n",
            "Epoch 45/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0074 - val_loss: 0.9409\n",
            "Epoch 46/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0074 - val_loss: 0.9409\n",
            "Epoch 47/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0073 - val_loss: 0.9408\n",
            "Epoch 48/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0073 - val_loss: 0.9408\n",
            "Epoch 49/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0073 - val_loss: 0.9408\n",
            "Epoch 50/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0072 - val_loss: 0.9407\n",
            "Epoch 51/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0072 - val_loss: 0.9407\n",
            "Epoch 52/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0072 - val_loss: 0.9407\n",
            "Epoch 53/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0071 - val_loss: 0.9407\n",
            "Epoch 54/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0071 - val_loss: 0.9407\n",
            "Epoch 55/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0071 - val_loss: 0.9407\n",
            "Epoch 56/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0071 - val_loss: 0.9406\n",
            "Epoch 57/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0070 - val_loss: 0.9406\n",
            "Epoch 58/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0070 - val_loss: 0.9406\n",
            "Epoch 59/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0070 - val_loss: 0.9406\n",
            "Epoch 60/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0070 - val_loss: 0.9406\n",
            "Epoch 61/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0070 - val_loss: 0.9406\n",
            "Epoch 62/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0069 - val_loss: 0.9406\n",
            "Epoch 63/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0069 - val_loss: 0.9406\n",
            "Epoch 64/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0069 - val_loss: 0.9406\n",
            "Epoch 65/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0069 - val_loss: 0.9406\n",
            "Epoch 66/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0069 - val_loss: 0.9405\n",
            "Epoch 67/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0069 - val_loss: 0.9405\n",
            "Epoch 68/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0069 - val_loss: 0.9405\n",
            "Epoch 69/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0069 - val_loss: 0.9405\n",
            "Epoch 70/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0068 - val_loss: 0.9405\n",
            "Epoch 71/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0068 - val_loss: 0.9405\n",
            "Epoch 72/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0068 - val_loss: 0.9405\n",
            "Epoch 73/100\n",
            "252/252 [==============================] - 1s 3ms/step - loss: 1.0068 - val_loss: 0.9405\n",
            "Epoch 74/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0068 - val_loss: 0.9405\n",
            "Epoch 75/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0068 - val_loss: 0.9405\n",
            "Epoch 76/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0068 - val_loss: 0.9405\n",
            "Epoch 77/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0068 - val_loss: 0.9405\n",
            "Epoch 78/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0068 - val_loss: 0.9405\n",
            "Epoch 79/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0068 - val_loss: 0.9405\n",
            "Epoch 80/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0068 - val_loss: 0.9405\n",
            "Epoch 81/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0068 - val_loss: 0.9405\n",
            "Epoch 82/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0068 - val_loss: 0.9405\n",
            "Epoch 83/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0068 - val_loss: 0.9405\n",
            "Epoch 84/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0068 - val_loss: 0.9405\n",
            "Epoch 85/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0068 - val_loss: 0.9405\n",
            "Epoch 86/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0067 - val_loss: 0.9405\n",
            "Epoch 87/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0067 - val_loss: 0.9405\n",
            "Epoch 88/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0067 - val_loss: 0.9405\n",
            "Epoch 89/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0067 - val_loss: 0.9405\n",
            "Epoch 90/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0067 - val_loss: 0.9405\n",
            "Epoch 91/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0067 - val_loss: 0.9405\n",
            "Epoch 92/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0067 - val_loss: 0.9405\n",
            "Epoch 93/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0067 - val_loss: 0.9405\n",
            "Epoch 94/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0067 - val_loss: 0.9405\n",
            "Epoch 95/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0067 - val_loss: 0.9405\n",
            "Epoch 96/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0067 - val_loss: 0.9405\n",
            "Epoch 97/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0067 - val_loss: 0.9405\n",
            "Epoch 98/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0067 - val_loss: 0.9405\n",
            "Epoch 99/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0067 - val_loss: 0.9405\n",
            "Epoch 100/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0067 - val_loss: 0.9405\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_67 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_55 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_68 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_56 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_69 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_57 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_70 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_58 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_71 (Dense)             (None, 1)                 2         \n",
            "=================================================================\n",
            "Total params: 10\n",
            "Trainable params: 10\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.2472 - val_loss: 1.3121\n",
            "Epoch 2/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.1841 - val_loss: 1.2575\n",
            "Epoch 3/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.1404 - val_loss: 1.2170\n",
            "Epoch 4/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.1079 - val_loss: 1.1865\n",
            "Epoch 5/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0836 - val_loss: 1.1630\n",
            "Epoch 6/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0652 - val_loss: 1.1452\n",
            "Epoch 7/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0513 - val_loss: 1.1314\n",
            "Epoch 8/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0405 - val_loss: 1.1207\n",
            "Epoch 9/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0321 - val_loss: 1.1120\n",
            "Epoch 10/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0254 - val_loss: 1.1050\n",
            "Epoch 11/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0202 - val_loss: 1.0995\n",
            "Epoch 12/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0160 - val_loss: 1.0949\n",
            "Epoch 13/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0126 - val_loss: 1.0912\n",
            "Epoch 14/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0098 - val_loss: 1.0879\n",
            "Epoch 15/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0074 - val_loss: 1.0852\n",
            "Epoch 16/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0054 - val_loss: 1.0829\n",
            "Epoch 17/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0038 - val_loss: 1.0810\n",
            "Epoch 18/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0025 - val_loss: 1.0793\n",
            "Epoch 19/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0013 - val_loss: 1.0778\n",
            "Epoch 20/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0003 - val_loss: 1.0765\n",
            "Epoch 21/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 1.0754\n",
            "Epoch 22/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9987 - val_loss: 1.0745\n",
            "Epoch 23/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9980 - val_loss: 1.0736\n",
            "Epoch 24/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9975 - val_loss: 1.0729\n",
            "Epoch 25/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9970 - val_loss: 1.0722\n",
            "Epoch 26/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9965 - val_loss: 1.0715\n",
            "Epoch 27/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9962 - val_loss: 1.0710\n",
            "Epoch 28/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9958 - val_loss: 1.0705\n",
            "Epoch 29/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9955 - val_loss: 1.0701\n",
            "Epoch 30/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9953 - val_loss: 1.0697\n",
            "Epoch 31/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9951 - val_loss: 1.0693\n",
            "Epoch 32/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9948 - val_loss: 1.0690\n",
            "Epoch 33/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9947 - val_loss: 1.0687\n",
            "Epoch 34/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9945 - val_loss: 1.0684\n",
            "Epoch 35/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9944 - val_loss: 1.0682\n",
            "Epoch 36/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9943 - val_loss: 1.0680\n",
            "Epoch 37/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9942 - val_loss: 1.0678\n",
            "Epoch 38/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9941 - val_loss: 1.0676\n",
            "Epoch 39/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9940 - val_loss: 1.0674\n",
            "Epoch 40/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9939 - val_loss: 1.0673\n",
            "Epoch 41/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9938 - val_loss: 1.0671\n",
            "Epoch 42/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9937 - val_loss: 1.0669\n",
            "Epoch 43/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9937 - val_loss: 1.0668\n",
            "Epoch 44/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9936 - val_loss: 1.0667\n",
            "Epoch 45/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9936 - val_loss: 1.0666\n",
            "Epoch 46/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9935 - val_loss: 1.0665\n",
            "Epoch 47/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9935 - val_loss: 1.0664\n",
            "Epoch 48/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9934 - val_loss: 1.0663\n",
            "Epoch 49/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9934 - val_loss: 1.0662\n",
            "Epoch 50/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9934 - val_loss: 1.0662\n",
            "Epoch 51/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9933 - val_loss: 1.0661\n",
            "Epoch 52/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9933 - val_loss: 1.0660\n",
            "Epoch 53/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9933 - val_loss: 1.0660\n",
            "Epoch 54/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9933 - val_loss: 1.0659\n",
            "Epoch 55/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9932 - val_loss: 1.0659\n",
            "Epoch 56/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9932 - val_loss: 1.0658\n",
            "Epoch 57/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9932 - val_loss: 1.0658\n",
            "Epoch 58/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9932 - val_loss: 1.0657\n",
            "Epoch 59/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9932 - val_loss: 1.0657\n",
            "Epoch 60/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9931 - val_loss: 1.0656\n",
            "Epoch 61/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9931 - val_loss: 1.0656\n",
            "Epoch 62/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9931 - val_loss: 1.0655\n",
            "Epoch 63/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9931 - val_loss: 1.0655\n",
            "Epoch 64/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9931 - val_loss: 1.0655\n",
            "Epoch 65/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9931 - val_loss: 1.0654\n",
            "Epoch 66/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9931 - val_loss: 1.0654\n",
            "Epoch 67/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9931 - val_loss: 1.0654\n",
            "Epoch 68/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9931 - val_loss: 1.0653\n",
            "Epoch 69/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9931 - val_loss: 1.0653\n",
            "Epoch 70/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9930 - val_loss: 1.0653\n",
            "Epoch 71/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9930 - val_loss: 1.0653\n",
            "Epoch 72/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9930 - val_loss: 1.0652\n",
            "Epoch 73/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9930 - val_loss: 1.0652\n",
            "Epoch 74/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9930 - val_loss: 1.0652\n",
            "Epoch 75/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9930 - val_loss: 1.0652\n",
            "Epoch 76/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9930 - val_loss: 1.0651\n",
            "Epoch 77/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9930 - val_loss: 1.0651\n",
            "Epoch 78/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9930 - val_loss: 1.0651\n",
            "Epoch 79/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9930 - val_loss: 1.0651\n",
            "Epoch 80/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9930 - val_loss: 1.0651\n",
            "Epoch 81/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9930 - val_loss: 1.0651\n",
            "Epoch 82/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9930 - val_loss: 1.0650\n",
            "Epoch 83/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9930 - val_loss: 1.0650\n",
            "Epoch 84/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9930 - val_loss: 1.0650\n",
            "Epoch 85/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9930 - val_loss: 1.0650\n",
            "Epoch 86/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9930 - val_loss: 1.0650\n",
            "Epoch 87/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9930 - val_loss: 1.0650\n",
            "Epoch 88/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9930 - val_loss: 1.0650\n",
            "Epoch 89/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9929 - val_loss: 1.0649\n",
            "Epoch 90/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9929 - val_loss: 1.0649\n",
            "Epoch 91/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9929 - val_loss: 1.0649\n",
            "Epoch 92/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9929 - val_loss: 1.0649\n",
            "Epoch 93/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9929 - val_loss: 1.0649\n",
            "Epoch 94/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9929 - val_loss: 1.0649\n",
            "Epoch 95/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9929 - val_loss: 1.0649\n",
            "Epoch 96/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9929 - val_loss: 1.0649\n",
            "Epoch 97/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9929 - val_loss: 1.0648\n",
            "Epoch 98/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9929 - val_loss: 1.0648\n",
            "Epoch 99/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9929 - val_loss: 1.0648\n",
            "Epoch 100/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9929 - val_loss: 1.0648\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_72 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_59 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_73 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_60 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_74 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_61 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_75 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_62 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_76 (Dense)             (None, 1)                 2         \n",
            "=================================================================\n",
            "Total params: 10\n",
            "Trainable params: 10\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "252/252 [==============================] - 1s 3ms/step - loss: 1.2946 - val_loss: 1.3575\n",
            "Epoch 2/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.2016 - val_loss: 1.2876\n",
            "Epoch 3/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.1478 - val_loss: 1.2397\n",
            "Epoch 4/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.1109 - val_loss: 1.2050\n",
            "Epoch 5/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0850 - val_loss: 1.1797\n",
            "Epoch 6/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0656 - val_loss: 1.1600\n",
            "Epoch 7/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0511 - val_loss: 1.1449\n",
            "Epoch 8/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0401 - val_loss: 1.1332\n",
            "Epoch 9/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0317 - val_loss: 1.1240\n",
            "Epoch 10/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0250 - val_loss: 1.1164\n",
            "Epoch 11/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0197 - val_loss: 1.1103\n",
            "Epoch 12/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0154 - val_loss: 1.1051\n",
            "Epoch 13/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0119 - val_loss: 1.1009\n",
            "Epoch 14/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0090 - val_loss: 1.0973\n",
            "Epoch 15/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0067 - val_loss: 1.0943\n",
            "Epoch 16/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0047 - val_loss: 1.0916\n",
            "Epoch 17/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0031 - val_loss: 1.0894\n",
            "Epoch 18/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0017 - val_loss: 1.0875\n",
            "Epoch 19/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0005 - val_loss: 1.0858\n",
            "Epoch 20/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 1.0843\n",
            "Epoch 21/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9986 - val_loss: 1.0831\n",
            "Epoch 22/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9979 - val_loss: 1.0819\n",
            "Epoch 23/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9973 - val_loss: 1.0809\n",
            "Epoch 24/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9967 - val_loss: 1.0801\n",
            "Epoch 25/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9962 - val_loss: 1.0792\n",
            "Epoch 26/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9958 - val_loss: 1.0785\n",
            "Epoch 27/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9955 - val_loss: 1.0779\n",
            "Epoch 28/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9951 - val_loss: 1.0773\n",
            "Epoch 29/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9948 - val_loss: 1.0768\n",
            "Epoch 30/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9946 - val_loss: 1.0763\n",
            "Epoch 31/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9944 - val_loss: 1.0759\n",
            "Epoch 32/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9942 - val_loss: 1.0755\n",
            "Epoch 33/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9940 - val_loss: 1.0752\n",
            "Epoch 34/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9939 - val_loss: 1.0748\n",
            "Epoch 35/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9937 - val_loss: 1.0745\n",
            "Epoch 36/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9936 - val_loss: 1.0742\n",
            "Epoch 37/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9935 - val_loss: 1.0740\n",
            "Epoch 38/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9934 - val_loss: 1.0738\n",
            "Epoch 39/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9933 - val_loss: 1.0736\n",
            "Epoch 40/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9932 - val_loss: 1.0734\n",
            "Epoch 41/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9932 - val_loss: 1.0732\n",
            "Epoch 42/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9931 - val_loss: 1.0730\n",
            "Epoch 43/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9930 - val_loss: 1.0729\n",
            "Epoch 44/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9930 - val_loss: 1.0727\n",
            "Epoch 45/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9930 - val_loss: 1.0726\n",
            "Epoch 46/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9929 - val_loss: 1.0725\n",
            "Epoch 47/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9929 - val_loss: 1.0723\n",
            "Epoch 48/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9928 - val_loss: 1.0722\n",
            "Epoch 49/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9928 - val_loss: 1.0721\n",
            "Epoch 50/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9928 - val_loss: 1.0720\n",
            "Epoch 51/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9927 - val_loss: 1.0719\n",
            "Epoch 52/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9927 - val_loss: 1.0718\n",
            "Epoch 53/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9927 - val_loss: 1.0718\n",
            "Epoch 54/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9927 - val_loss: 1.0717\n",
            "Epoch 55/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9926 - val_loss: 1.0716\n",
            "Epoch 56/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9926 - val_loss: 1.0716\n",
            "Epoch 57/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9926 - val_loss: 1.0715\n",
            "Epoch 58/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9926 - val_loss: 1.0714\n",
            "Epoch 59/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9926 - val_loss: 1.0714\n",
            "Epoch 60/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9926 - val_loss: 1.0713\n",
            "Epoch 61/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9926 - val_loss: 1.0713\n",
            "Epoch 62/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9925 - val_loss: 1.0712\n",
            "Epoch 63/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9925 - val_loss: 1.0712\n",
            "Epoch 64/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9925 - val_loss: 1.0711\n",
            "Epoch 65/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9925 - val_loss: 1.0711\n",
            "Epoch 66/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9925 - val_loss: 1.0710\n",
            "Epoch 67/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9925 - val_loss: 1.0710\n",
            "Epoch 68/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9925 - val_loss: 1.0710\n",
            "Epoch 69/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9925 - val_loss: 1.0709\n",
            "Epoch 70/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9925 - val_loss: 1.0709\n",
            "Epoch 71/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9925 - val_loss: 1.0709\n",
            "Epoch 72/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9924 - val_loss: 1.0708\n",
            "Epoch 73/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9924 - val_loss: 1.0708\n",
            "Epoch 74/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9924 - val_loss: 1.0708\n",
            "Epoch 75/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9924 - val_loss: 1.0707\n",
            "Epoch 76/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9924 - val_loss: 1.0707\n",
            "Epoch 77/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9924 - val_loss: 1.0707\n",
            "Epoch 78/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9924 - val_loss: 1.0706\n",
            "Epoch 79/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9924 - val_loss: 1.0706\n",
            "Epoch 80/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9924 - val_loss: 1.0706\n",
            "Epoch 81/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9924 - val_loss: 1.0706\n",
            "Epoch 82/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9924 - val_loss: 1.0705\n",
            "Epoch 83/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9924 - val_loss: 1.0705\n",
            "Epoch 84/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9924 - val_loss: 1.0705\n",
            "Epoch 85/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9924 - val_loss: 1.0705\n",
            "Epoch 86/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9924 - val_loss: 1.0704\n",
            "Epoch 87/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9924 - val_loss: 1.0704\n",
            "Epoch 88/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9924 - val_loss: 1.0704\n",
            "Epoch 89/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9924 - val_loss: 1.0704\n",
            "Epoch 90/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9924 - val_loss: 1.0704\n",
            "Epoch 91/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9924 - val_loss: 1.0704\n",
            "Epoch 92/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9924 - val_loss: 1.0704\n",
            "Epoch 93/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9924 - val_loss: 1.0703\n",
            "Epoch 94/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9924 - val_loss: 1.0703\n",
            "Epoch 95/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9924 - val_loss: 1.0703\n",
            "Epoch 96/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9924 - val_loss: 1.0703\n",
            "Epoch 97/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9924 - val_loss: 1.0703\n",
            "Epoch 98/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9924 - val_loss: 1.0703\n",
            "Epoch 99/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9924 - val_loss: 1.0703\n",
            "Epoch 100/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9924 - val_loss: 1.0702\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_77 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_63 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_78 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_64 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_79 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_65 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_80 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_66 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_81 (Dense)             (None, 1)                 2         \n",
            "=================================================================\n",
            "Total params: 10\n",
            "Trainable params: 10\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "252/252 [==============================] - 1s 3ms/step - loss: 1.2402 - val_loss: 1.2691\n",
            "Epoch 2/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.1856 - val_loss: 1.2176\n",
            "Epoch 3/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.1439 - val_loss: 1.1773\n",
            "Epoch 4/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.1119 - val_loss: 1.1467\n",
            "Epoch 5/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0881 - val_loss: 1.1232\n",
            "Epoch 6/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0700 - val_loss: 1.1051\n",
            "Epoch 7/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0559 - val_loss: 1.0910\n",
            "Epoch 8/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0452 - val_loss: 1.0797\n",
            "Epoch 9/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0369 - val_loss: 1.0709\n",
            "Epoch 10/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0303 - val_loss: 1.0639\n",
            "Epoch 11/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0251 - val_loss: 1.0581\n",
            "Epoch 12/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0209 - val_loss: 1.0533\n",
            "Epoch 13/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0174 - val_loss: 1.0493\n",
            "Epoch 14/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0146 - val_loss: 1.0459\n",
            "Epoch 15/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0123 - val_loss: 1.0431\n",
            "Epoch 16/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0103 - val_loss: 1.0406\n",
            "Epoch 17/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0087 - val_loss: 1.0386\n",
            "Epoch 18/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0073 - val_loss: 1.0368\n",
            "Epoch 19/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0061 - val_loss: 1.0353\n",
            "Epoch 20/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0051 - val_loss: 1.0339\n",
            "Epoch 21/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0042 - val_loss: 1.0327\n",
            "Epoch 22/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0035 - val_loss: 1.0316\n",
            "Epoch 23/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0028 - val_loss: 1.0306\n",
            "Epoch 24/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0022 - val_loss: 1.0298\n",
            "Epoch 25/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0018 - val_loss: 1.0291\n",
            "Epoch 26/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0013 - val_loss: 1.0285\n",
            "Epoch 27/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0010 - val_loss: 1.0279\n",
            "Epoch 28/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0007 - val_loss: 1.0273\n",
            "Epoch 29/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0004 - val_loss: 1.0268\n",
            "Epoch 30/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0001 - val_loss: 1.0264\n",
            "Epoch 31/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 1.0260\n",
            "Epoch 32/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9997 - val_loss: 1.0256\n",
            "Epoch 33/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9995 - val_loss: 1.0254\n",
            "Epoch 34/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9994 - val_loss: 1.0251\n",
            "Epoch 35/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9992 - val_loss: 1.0248\n",
            "Epoch 36/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9991 - val_loss: 1.0246\n",
            "Epoch 37/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9990 - val_loss: 1.0244\n",
            "Epoch 38/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9989 - val_loss: 1.0241\n",
            "Epoch 39/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9988 - val_loss: 1.0239\n",
            "Epoch 40/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 1.0238\n",
            "Epoch 41/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 1.0236\n",
            "Epoch 42/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9986 - val_loss: 1.0235\n",
            "Epoch 43/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9985 - val_loss: 1.0233\n",
            "Epoch 44/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9985 - val_loss: 1.0232\n",
            "Epoch 45/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9984 - val_loss: 1.0231\n",
            "Epoch 46/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 1.0230\n",
            "Epoch 47/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9983 - val_loss: 1.0229\n",
            "Epoch 48/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9983 - val_loss: 1.0228\n",
            "Epoch 49/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9983 - val_loss: 1.0227\n",
            "Epoch 50/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9982 - val_loss: 1.0226\n",
            "Epoch 51/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9982 - val_loss: 1.0225\n",
            "Epoch 52/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9982 - val_loss: 1.0224\n",
            "Epoch 53/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9982 - val_loss: 1.0224\n",
            "Epoch 54/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9981 - val_loss: 1.0223\n",
            "Epoch 55/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9981 - val_loss: 1.0222\n",
            "Epoch 56/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9981 - val_loss: 1.0222\n",
            "Epoch 57/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9981 - val_loss: 1.0221\n",
            "Epoch 58/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9981 - val_loss: 1.0221\n",
            "Epoch 59/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9980 - val_loss: 1.0220\n",
            "Epoch 60/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9980 - val_loss: 1.0220\n",
            "Epoch 61/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9980 - val_loss: 1.0219\n",
            "Epoch 62/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9980 - val_loss: 1.0219\n",
            "Epoch 63/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9980 - val_loss: 1.0218\n",
            "Epoch 64/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9980 - val_loss: 1.0218\n",
            "Epoch 65/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9980 - val_loss: 1.0217\n",
            "Epoch 66/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9979 - val_loss: 1.0217\n",
            "Epoch 67/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9979 - val_loss: 1.0217\n",
            "Epoch 68/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9979 - val_loss: 1.0216\n",
            "Epoch 69/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9979 - val_loss: 1.0216\n",
            "Epoch 70/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9979 - val_loss: 1.0216\n",
            "Epoch 71/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9979 - val_loss: 1.0216\n",
            "Epoch 72/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9979 - val_loss: 1.0215\n",
            "Epoch 73/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9979 - val_loss: 1.0215\n",
            "Epoch 74/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9979 - val_loss: 1.0215\n",
            "Epoch 75/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9979 - val_loss: 1.0215\n",
            "Epoch 76/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9979 - val_loss: 1.0214\n",
            "Epoch 77/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9979 - val_loss: 1.0214\n",
            "Epoch 78/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9979 - val_loss: 1.0214\n",
            "Epoch 79/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9979 - val_loss: 1.0214\n",
            "Epoch 80/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9979 - val_loss: 1.0213\n",
            "Epoch 81/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9979 - val_loss: 1.0213\n",
            "Epoch 82/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9978 - val_loss: 1.0213\n",
            "Epoch 83/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9978 - val_loss: 1.0213\n",
            "Epoch 84/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9978 - val_loss: 1.0213\n",
            "Epoch 85/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9978 - val_loss: 1.0212\n",
            "Epoch 86/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9978 - val_loss: 1.0212\n",
            "Epoch 87/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9978 - val_loss: 1.0212\n",
            "Epoch 88/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9978 - val_loss: 1.0212\n",
            "Epoch 89/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9978 - val_loss: 1.0212\n",
            "Epoch 90/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9978 - val_loss: 1.0212\n",
            "Epoch 91/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9978 - val_loss: 1.0212\n",
            "Epoch 92/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9978 - val_loss: 1.0211\n",
            "Epoch 93/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9978 - val_loss: 1.0211\n",
            "Epoch 94/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9978 - val_loss: 1.0211\n",
            "Epoch 95/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9978 - val_loss: 1.0211\n",
            "Epoch 96/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9978 - val_loss: 1.0211\n",
            "Epoch 97/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9978 - val_loss: 1.0211\n",
            "Epoch 98/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9978 - val_loss: 1.0211\n",
            "Epoch 99/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9978 - val_loss: 1.0210\n",
            "Epoch 100/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9978 - val_loss: 1.0210\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_82 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_67 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_83 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_68 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_84 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_69 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_85 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_70 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_86 (Dense)             (None, 1)                 2         \n",
            "=================================================================\n",
            "Total params: 10\n",
            "Trainable params: 10\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "252/252 [==============================] - 1s 3ms/step - loss: 1.2672 - val_loss: 1.2469\n",
            "Epoch 2/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.1987 - val_loss: 1.1904\n",
            "Epoch 3/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.1521 - val_loss: 1.1500\n",
            "Epoch 4/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.1184 - val_loss: 1.1197\n",
            "Epoch 5/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0931 - val_loss: 1.0970\n",
            "Epoch 6/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0742 - val_loss: 1.0797\n",
            "Epoch 7/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0598 - val_loss: 1.0661\n",
            "Epoch 8/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0486 - val_loss: 1.0557\n",
            "Epoch 9/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0400 - val_loss: 1.0475\n",
            "Epoch 10/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0333 - val_loss: 1.0409\n",
            "Epoch 11/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0279 - val_loss: 1.0357\n",
            "Epoch 12/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0235 - val_loss: 1.0313\n",
            "Epoch 13/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0199 - val_loss: 1.0277\n",
            "Epoch 14/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0170 - val_loss: 1.0248\n",
            "Epoch 15/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0146 - val_loss: 1.0222\n",
            "Epoch 16/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0126 - val_loss: 1.0201\n",
            "Epoch 17/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0109 - val_loss: 1.0183\n",
            "Epoch 18/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0094 - val_loss: 1.0168\n",
            "Epoch 19/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0082 - val_loss: 1.0155\n",
            "Epoch 20/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0072 - val_loss: 1.0144\n",
            "Epoch 21/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0063 - val_loss: 1.0134\n",
            "Epoch 22/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0056 - val_loss: 1.0125\n",
            "Epoch 23/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0049 - val_loss: 1.0117\n",
            "Epoch 24/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0043 - val_loss: 1.0111\n",
            "Epoch 25/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0038 - val_loss: 1.0105\n",
            "Epoch 26/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0033 - val_loss: 1.0100\n",
            "Epoch 27/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0029 - val_loss: 1.0095\n",
            "Epoch 28/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 1.0091\n",
            "Epoch 29/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0023 - val_loss: 1.0087\n",
            "Epoch 30/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0021 - val_loss: 1.0084\n",
            "Epoch 31/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0018 - val_loss: 1.0081\n",
            "Epoch 32/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0016 - val_loss: 1.0078\n",
            "Epoch 33/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0014 - val_loss: 1.0076\n",
            "Epoch 34/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0013 - val_loss: 1.0074\n",
            "Epoch 35/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0011 - val_loss: 1.0072\n",
            "Epoch 36/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0010 - val_loss: 1.0070\n",
            "Epoch 37/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0009 - val_loss: 1.0068\n",
            "Epoch 38/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0008 - val_loss: 1.0067\n",
            "Epoch 39/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0007 - val_loss: 1.0066\n",
            "Epoch 40/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0006 - val_loss: 1.0064\n",
            "Epoch 41/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0005 - val_loss: 1.0063\n",
            "Epoch 42/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0004 - val_loss: 1.0062\n",
            "Epoch 43/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0004 - val_loss: 1.0061\n",
            "Epoch 44/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0003 - val_loss: 1.0060\n",
            "Epoch 45/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0003 - val_loss: 1.0060\n",
            "Epoch 46/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0002 - val_loss: 1.0059\n",
            "Epoch 47/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0002 - val_loss: 1.0058\n",
            "Epoch 48/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0001 - val_loss: 1.0057\n",
            "Epoch 49/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0001 - val_loss: 1.0057\n",
            "Epoch 50/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0000 - val_loss: 1.0056\n",
            "Epoch 51/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0000 - val_loss: 1.0055\n",
            "Epoch 52/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0000 - val_loss: 1.0055\n",
            "Epoch 53/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0000 - val_loss: 1.0055\n",
            "Epoch 54/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9999 - val_loss: 1.0054\n",
            "Epoch 55/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9999 - val_loss: 1.0054\n",
            "Epoch 56/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9999 - val_loss: 1.0053\n",
            "Epoch 57/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9999 - val_loss: 1.0053\n",
            "Epoch 58/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9999 - val_loss: 1.0053\n",
            "Epoch 59/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9998 - val_loss: 1.0052\n",
            "Epoch 60/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9998 - val_loss: 1.0052\n",
            "Epoch 61/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9998 - val_loss: 1.0052\n",
            "Epoch 62/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9998 - val_loss: 1.0052\n",
            "Epoch 63/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9998 - val_loss: 1.0051\n",
            "Epoch 64/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9998 - val_loss: 1.0051\n",
            "Epoch 65/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9998 - val_loss: 1.0051\n",
            "Epoch 66/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9998 - val_loss: 1.0051\n",
            "Epoch 67/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9997 - val_loss: 1.0051\n",
            "Epoch 68/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9997 - val_loss: 1.0050\n",
            "Epoch 69/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9997 - val_loss: 1.0050\n",
            "Epoch 70/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9997 - val_loss: 1.0050\n",
            "Epoch 71/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9997 - val_loss: 1.0050\n",
            "Epoch 72/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9997 - val_loss: 1.0050\n",
            "Epoch 73/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9997 - val_loss: 1.0050\n",
            "Epoch 74/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9997 - val_loss: 1.0049\n",
            "Epoch 75/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9997 - val_loss: 1.0049\n",
            "Epoch 76/100\n",
            "252/252 [==============================] - 1s 3ms/step - loss: 0.9997 - val_loss: 1.0049\n",
            "Epoch 77/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9997 - val_loss: 1.0049\n",
            "Epoch 78/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9997 - val_loss: 1.0049\n",
            "Epoch 79/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9997 - val_loss: 1.0049\n",
            "Epoch 80/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9997 - val_loss: 1.0049\n",
            "Epoch 81/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9997 - val_loss: 1.0049\n",
            "Epoch 82/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9997 - val_loss: 1.0048\n",
            "Epoch 83/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9996 - val_loss: 1.0048\n",
            "Epoch 84/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9996 - val_loss: 1.0048\n",
            "Epoch 85/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9996 - val_loss: 1.0048\n",
            "Epoch 86/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9996 - val_loss: 1.0048\n",
            "Epoch 87/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9996 - val_loss: 1.0048\n",
            "Epoch 88/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9996 - val_loss: 1.0048\n",
            "Epoch 89/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 1.0048\n",
            "Epoch 90/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9996 - val_loss: 1.0048\n",
            "Epoch 91/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9996 - val_loss: 1.0048\n",
            "Epoch 92/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9996 - val_loss: 1.0048\n",
            "Epoch 93/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9996 - val_loss: 1.0047\n",
            "Epoch 94/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9996 - val_loss: 1.0047\n",
            "Epoch 95/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9996 - val_loss: 1.0047\n",
            "Epoch 96/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9996 - val_loss: 1.0047\n",
            "Epoch 97/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9996 - val_loss: 1.0047\n",
            "Epoch 98/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9996 - val_loss: 1.0047\n",
            "Epoch 99/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9996 - val_loss: 1.0047\n",
            "Epoch 100/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 0.9996 - val_loss: 1.0047\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_87 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_71 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_88 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_72 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_89 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_73 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_90 (Dense)             (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "dropout_74 (Dropout)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_91 (Dense)             (None, 1)                 2         \n",
            "=================================================================\n",
            "Total params: 10\n",
            "Trainable params: 10\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "252/252 [==============================] - 2s 3ms/step - loss: 1.2676 - val_loss: 1.2191\n",
            "Epoch 2/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.1979 - val_loss: 1.1624\n",
            "Epoch 3/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.1508 - val_loss: 1.1231\n",
            "Epoch 4/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.1175 - val_loss: 1.0950\n",
            "Epoch 5/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0931 - val_loss: 1.0739\n",
            "Epoch 6/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0746 - val_loss: 1.0576\n",
            "Epoch 7/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0604 - val_loss: 1.0452\n",
            "Epoch 8/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0496 - val_loss: 1.0356\n",
            "Epoch 9/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0411 - val_loss: 1.0280\n",
            "Epoch 10/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0345 - val_loss: 1.0221\n",
            "Epoch 11/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0291 - val_loss: 1.0173\n",
            "Epoch 12/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0247 - val_loss: 1.0133\n",
            "Epoch 13/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0213 - val_loss: 1.0102\n",
            "Epoch 14/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0185 - val_loss: 1.0076\n",
            "Epoch 15/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0162 - val_loss: 1.0054\n",
            "Epoch 16/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0142 - val_loss: 1.0035\n",
            "Epoch 17/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0125 - val_loss: 1.0020\n",
            "Epoch 18/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0111 - val_loss: 1.0007\n",
            "Epoch 19/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0099 - val_loss: 0.9995\n",
            "Epoch 20/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0088 - val_loss: 0.9986\n",
            "Epoch 21/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0079 - val_loss: 0.9977\n",
            "Epoch 22/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0071 - val_loss: 0.9969\n",
            "Epoch 23/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0064 - val_loss: 0.9963\n",
            "Epoch 24/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0058 - val_loss: 0.9958\n",
            "Epoch 25/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0053 - val_loss: 0.9953\n",
            "Epoch 26/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0049 - val_loss: 0.9949\n",
            "Epoch 27/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0045 - val_loss: 0.9945\n",
            "Epoch 28/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0042 - val_loss: 0.9942\n",
            "Epoch 29/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0039 - val_loss: 0.9939\n",
            "Epoch 30/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0036 - val_loss: 0.9936\n",
            "Epoch 31/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0034 - val_loss: 0.9934\n",
            "Epoch 32/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0032 - val_loss: 0.9932\n",
            "Epoch 33/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0030 - val_loss: 0.9930\n",
            "Epoch 34/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0028 - val_loss: 0.9928\n",
            "Epoch 35/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0027 - val_loss: 0.9927\n",
            "Epoch 36/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0025 - val_loss: 0.9926\n",
            "Epoch 37/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0024 - val_loss: 0.9925\n",
            "Epoch 38/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0023 - val_loss: 0.9923\n",
            "Epoch 39/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0022 - val_loss: 0.9923\n",
            "Epoch 40/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0021 - val_loss: 0.9922\n",
            "Epoch 41/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0020 - val_loss: 0.9921\n",
            "Epoch 42/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0020 - val_loss: 0.9920\n",
            "Epoch 43/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0019 - val_loss: 0.9920\n",
            "Epoch 44/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0018 - val_loss: 0.9919\n",
            "Epoch 45/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0018 - val_loss: 0.9918\n",
            "Epoch 46/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0017 - val_loss: 0.9918\n",
            "Epoch 47/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0017 - val_loss: 0.9917\n",
            "Epoch 48/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0017 - val_loss: 0.9917\n",
            "Epoch 49/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0016 - val_loss: 0.9917\n",
            "Epoch 50/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0016 - val_loss: 0.9916\n",
            "Epoch 51/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0015 - val_loss: 0.9916\n",
            "Epoch 52/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0015 - val_loss: 0.9916\n",
            "Epoch 53/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0015 - val_loss: 0.9915\n",
            "Epoch 54/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0015 - val_loss: 0.9915\n",
            "Epoch 55/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0014 - val_loss: 0.9915\n",
            "Epoch 56/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0014 - val_loss: 0.9915\n",
            "Epoch 57/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0014 - val_loss: 0.9914\n",
            "Epoch 58/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0014 - val_loss: 0.9914\n",
            "Epoch 59/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0014 - val_loss: 0.9914\n",
            "Epoch 60/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0013 - val_loss: 0.9914\n",
            "Epoch 61/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0013 - val_loss: 0.9914\n",
            "Epoch 62/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0013 - val_loss: 0.9914\n",
            "Epoch 63/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0013 - val_loss: 0.9913\n",
            "Epoch 64/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0013 - val_loss: 0.9913\n",
            "Epoch 65/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0013 - val_loss: 0.9913\n",
            "Epoch 66/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0013 - val_loss: 0.9913\n",
            "Epoch 67/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0013 - val_loss: 0.9913\n",
            "Epoch 68/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0012 - val_loss: 0.9913\n",
            "Epoch 69/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0012 - val_loss: 0.9913\n",
            "Epoch 70/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0012 - val_loss: 0.9913\n",
            "Epoch 71/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0012 - val_loss: 0.9912\n",
            "Epoch 72/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0012 - val_loss: 0.9912\n",
            "Epoch 73/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0012 - val_loss: 0.9912\n",
            "Epoch 74/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0012 - val_loss: 0.9912\n",
            "Epoch 75/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0012 - val_loss: 0.9912\n",
            "Epoch 76/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0012 - val_loss: 0.9912\n",
            "Epoch 77/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0012 - val_loss: 0.9912\n",
            "Epoch 78/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0012 - val_loss: 0.9912\n",
            "Epoch 79/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0012 - val_loss: 0.9912\n",
            "Epoch 80/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0012 - val_loss: 0.9912\n",
            "Epoch 81/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0011 - val_loss: 0.9912\n",
            "Epoch 82/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0011 - val_loss: 0.9912\n",
            "Epoch 83/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0011 - val_loss: 0.9912\n",
            "Epoch 84/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0011 - val_loss: 0.9912\n",
            "Epoch 85/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0011 - val_loss: 0.9912\n",
            "Epoch 86/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0011 - val_loss: 0.9911\n",
            "Epoch 87/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0011 - val_loss: 0.9911\n",
            "Epoch 88/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0011 - val_loss: 0.9911\n",
            "Epoch 89/100\n",
            "252/252 [==============================] - 0s 2ms/step - loss: 1.0011 - val_loss: 0.9911\n",
            "Epoch 90/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0011 - val_loss: 0.9911\n",
            "Epoch 91/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0011 - val_loss: 0.9911\n",
            "Epoch 92/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0011 - val_loss: 0.9911\n",
            "Epoch 93/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0011 - val_loss: 0.9911\n",
            "Epoch 94/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0011 - val_loss: 0.9911\n",
            "Epoch 95/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0011 - val_loss: 0.9911\n",
            "Epoch 96/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0011 - val_loss: 0.9911\n",
            "Epoch 97/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0011 - val_loss: 0.9911\n",
            "Epoch 98/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0011 - val_loss: 0.9911\n",
            "Epoch 99/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0011 - val_loss: 0.9911\n",
            "Epoch 100/100\n",
            "252/252 [==============================] - 1s 2ms/step - loss: 1.0011 - val_loss: 0.9911\n",
            "\n",
            "Script Execution Time\n",
            "--------------------------\n",
            "It took 666.1 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}